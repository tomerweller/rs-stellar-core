use std::collections::HashMap;
use std::sync::Arc;

use axum::{
    extract::{Path, State},
    http::StatusCode,
    routing::get,
    Router,
};
use flate2::{write::GzEncoder, Compression};
use stellar_core_bucket::{Bucket, BucketList, BUCKET_LIST_LEVELS};
use stellar_core_common::Hash256;
use stellar_core_db::Database;
use stellar_core_history::{
    archive::HistoryArchive,
    archive_state::{HASBucketLevel, HistoryArchiveState},
    catchup::{CatchupManagerBuilder, CatchupOptions},
    paths::{checkpoint_path},
    verify,
};
use stellar_core_ledger::TransactionSetVariant;
use stellar_xdr::curr::{
    Hash, LedgerHeader, LedgerHeaderExt, LedgerHeaderHistoryEntry, LedgerHeaderHistoryEntryExt,
    StellarValue, StellarValueExt, TimePoint, TransactionResultSet, TransactionSet, VecM, WriteXdr,
};
use tokio::net::TcpListener;

fn gzip_bytes(data: &[u8]) -> Vec<u8> {
    let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
    use std::io::Write;
    encoder.write_all(data).expect("gzip write");
    encoder.finish().expect("gzip finish")
}

fn make_header(
    ledger_seq: u32,
    prev_hash: Hash256,
    bucket_list_hash: Hash256,
    tx_set_hash: Hash256,
    tx_result_hash: Hash256,
) -> LedgerHeader {
    LedgerHeader {
        ledger_version: 25,
        previous_ledger_hash: Hash(*prev_hash.as_bytes()),
        scp_value: StellarValue {
            tx_set_hash: Hash(*tx_set_hash.as_bytes()),
            close_time: TimePoint(0),
            upgrades: VecM::default(),
            ext: StellarValueExt::Basic,
        },
        tx_set_result_hash: Hash(*tx_result_hash.as_bytes()),
        bucket_list_hash: Hash(*bucket_list_hash.as_bytes()),
        ledger_seq,
        total_coins: 1_000_000,
        fee_pool: 0,
        inflation_seq: 0,
        id_pool: 0,
        base_fee: 100,
        base_reserve: 100,
        max_tx_set_size: 100,
        skip_list: [
            Hash([0u8; 32]),
            Hash([0u8; 32]),
            Hash([0u8; 32]),
            Hash([0u8; 32]),
        ],
        ext: LedgerHeaderExt::V0,
    }
}

fn empty_bucket_list() -> BucketList {
    let hashes = vec![Hash256::ZERO; BUCKET_LIST_LEVELS * 2];
    let load_bucket = |hash: &Hash256| -> stellar_core_bucket::Result<Bucket> {
        if hash.is_zero() {
            return Ok(Bucket::empty());
        }
        Bucket::from_xdr_bytes(&[])
    };
    BucketList::restore_from_hashes(&hashes, load_bucket).expect("restore bucket list")
}

#[tokio::test]
async fn test_catchup_replay_bucket_hash_verification() {
    let checkpoint = 63u32;
    let target = 64u32;

    let bucket_list = empty_bucket_list();
    let checkpoint_bucket_hash = bucket_list.hash();
    let mut bucket_list_after = bucket_list.clone();
    bucket_list_after
        .add_batch(
            target,
            25,
            stellar_xdr::curr::BucketListType::Live,
            Vec::new(),
            Vec::new(),
            Vec::new(),
        )
        .expect("bucket add batch");
    let replay_bucket_hash = bucket_list_after.hash();

    let header63 = make_header(
        checkpoint,
        Hash256::ZERO,
        checkpoint_bucket_hash,
        Hash256::ZERO,
        Hash256::ZERO,
    );
    let header63_hash = verify::compute_header_hash(&header63).expect("header63 hash");

    let tx_set = TransactionSet {
        previous_ledger_hash: Hash(*header63_hash.as_bytes()),
        txs: VecM::default(),
    };
    let tx_set_hash =
        verify::compute_tx_set_hash(&TransactionSetVariant::Classic(tx_set.clone()))
            .expect("tx set hash");

    let result_set = TransactionResultSet {
        results: VecM::default(),
    };
    let result_xdr = result_set
        .to_xdr(stellar_xdr::curr::Limits::none())
        .expect("tx result xdr");
    let tx_result_hash = Hash256::hash(&result_xdr);

    let header64 = make_header(
        target,
        header63_hash,
        replay_bucket_hash,
        tx_set_hash,
        tx_result_hash,
    );

    let headers_xdr = {
        let entry63 = LedgerHeaderHistoryEntry {
            hash: Hash([0u8; 32]),
            header: header63,
            ext: LedgerHeaderHistoryEntryExt::default(),
        };
        let entry64 = LedgerHeaderHistoryEntry {
            hash: Hash([0u8; 32]),
            header: header64,
            ext: LedgerHeaderHistoryEntryExt::default(),
        };
        let mut bytes = entry63
            .to_xdr(stellar_xdr::curr::Limits::none())
            .expect("header63 xdr");
        bytes.extend_from_slice(
            &entry64
                .to_xdr(stellar_xdr::curr::Limits::none())
                .expect("header64 xdr"),
        );
        bytes
    };

    let mut levels = Vec::with_capacity(BUCKET_LIST_LEVELS);
    for _ in 0..BUCKET_LIST_LEVELS {
        levels.push(HASBucketLevel {
            curr: "0".repeat(64),
            snap: "0".repeat(64),
            next: Default::default(),
        });
    }

    let has = HistoryArchiveState {
        version: 2,
        server: Some("rs-stellar-core test".to_string()),
        current_ledger: checkpoint,
        network_passphrase: Some("Test SDF Network ; September 2015".to_string()),
        current_buckets: levels,
        hot_archive_buckets: None,
    };

    let mut fixtures: HashMap<String, Vec<u8>> = HashMap::new();
    fixtures.insert(
        checkpoint_path("history", checkpoint, "json"),
        has.to_json().unwrap().into_bytes(),
    );
    fixtures.insert(
        checkpoint_path("ledger", checkpoint, "xdr.gz"),
        gzip_bytes(&headers_xdr),
    );
    fixtures.insert(
        checkpoint_path("transactions", checkpoint, "xdr.gz"),
        gzip_bytes(&[]),
    );
    fixtures.insert(
        checkpoint_path("results", checkpoint, "xdr.gz"),
        gzip_bytes(&[]),
    );

    let fixtures = Arc::new(fixtures);
    let app = Router::new()
        .route(
            "/*path",
            get(
                |Path(path): Path<String>, State(state): State<Arc<HashMap<String, Vec<u8>>>>| async move {
                    let key = path.trim_start_matches('/');
                    if let Some(body) = state.get(key) {
                        (StatusCode::OK, body.clone())
                    } else {
                        (StatusCode::NOT_FOUND, Vec::new())
                    }
                },
            ),
        )
        .with_state(Arc::clone(&fixtures));

    let listener = match TcpListener::bind("127.0.0.1:0").await {
        Ok(listener) => listener,
        Err(err) if err.kind() == std::io::ErrorKind::PermissionDenied => {
            eprintln!("skipping test: tcp bind not permitted in this environment");
            return;
        }
        Err(err) => panic!("bind: {err}"),
    };
    let addr = listener.local_addr().expect("addr");
    tokio::spawn(async move {
        axum::serve(listener, app).await.expect("serve");
    });

    let base_url = format!("http://{}/", addr);
    let archive = HistoryArchive::new(&base_url).expect("archive");

    let bucket_dir = tempfile::tempdir().expect("bucket dir");
    let bucket_manager = stellar_core_bucket::BucketManager::new(bucket_dir.path().to_path_buf())
        .expect("bucket manager");
    let db = Database::open_in_memory().expect("db");

    let mut manager = CatchupManagerBuilder::new()
        .add_archive(archive)
        .bucket_manager(bucket_manager)
        .database(db)
        .options(CatchupOptions {
            verify_buckets: true,
            verify_headers: true,
            ..CatchupOptions::default()
        })
        .build()
        .expect("catchup manager");

    let output = manager
        .catchup_to_ledger(target)
        .await
        .expect("catchup");

    assert_eq!(output.result.ledger_seq, target);
    assert_eq!(output.result.ledgers_applied, 1);
    assert_eq!(output.header.bucket_list_hash.0, *replay_bucket_hash.as_bytes());
}
